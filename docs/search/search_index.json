{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Semblance AI Documentation","text":"<p>Semblance AI is an experimental project to create a personalized AI that mirrors an individual's knowledge, values, and creativity through Personal Knowledge Augmented Generation (KAG). This documentation hub provides an overview of the project, shared standards, and links to sub-repositories.</p> <p>Use the navigation to explore the project vision, guidelines, and resources. For full documentation visit mkdocs.org.</p>"},{"location":"overview/project-vision/","title":"Project Vision","text":"<p>Semblance AI aims to craft a digital \"semblance\" of an individual by post-training a base AI model with user-curated data\u2014books, films, personal writings, and ethical frameworks. Unlike traditional AI assistants, Semblance AI is deeply personalized, acting as an intellectual sparring partner, creative collaborator, and digital legacy.</p> <p>No, it is not intended to be some kind striving for immortality, though the idea of my 'semblance' becoming part of the digital aether is an interesting possibility; the intention is for it to be a foundation for personal experiments in machine learning epistemology, reasoning abilities and testing/validation efforts. Perhaps more some day...</p> <p>If you would like to follow articles I publish that directly or indirectly arise from this project, please head over to Medium where you can find my writings:  https://eooo.medium.com/</p> <p>Learn more about the concept of KAG and its applications in the Sub-Repositories section.</p>"},{"location":"resources/faq/","title":"Frequently Asked Questions","text":""},{"location":"resources/tools-checklist/","title":"Toolchain for Semblance AI","text":""},{"location":"resources/tools-checklist/#full-toolchain-checklist-from-data-curation-to-benchmarking","title":"Full Toolchain Checklist (from Data Curation to Benchmarking)","text":""},{"location":"resources/tools-checklist/#1-data-collection-curation","title":"1. Data Collection &amp; Curation","text":"<ul> <li>[ ] <code>Scrapy</code> \u2013 Web scraping for user-approved online content (e.g., personal blogs) [Hybrid]</li> <li>[ ] <code>BeautifulSoup</code> \u2013 Lightweight web parsing for specific data extraction [Local]</li> <li>[ ] <code>yt-dlp</code> \u2013 Video/audio scraping for personal media (e.g., YouTube playlists) [Local]</li> <li>[ ] <code>ffmpeg</code> \u2013 Multimedia processing for video/audio extraction [Local]</li> <li>[ ] <code>pdfminer.six</code> \u2013 PDF parsing for documents (e.g., personal papers) [Local]</li> <li>[ ] <code>PyMuPDF</code> \u2013 High-performance PDF and document parsing [Local]</li> <li>[ ] <code>unstructured</code> \u2013 Parsing complex documents (e.g., mixed text/image files) [Local]</li> <li>[ ] <code>pypandoc</code> \u2013 Document format conversion (e.g., Markdown to text) [Local]</li> <li>[ ] <code>ebooklib</code> \u2013 Parsing ePub files for personal book collections [Local] (Added for niche formats)</li> <li>[ ] <code>music21</code> \u2013 Analyzing music scores or metadata for musical preferences [Local] (Added for music data)</li> <li>[ ] <code>Label Studio</code> \u2013 Annotation for tagging personal data (e.g., ethical stances) [Hybrid]</li> <li>[ ] <code>Streamlit</code> \u2013 User-friendly interface for manual data upload/tagging [Local] (Added for user interaction)</li> <li>[ ] <code>pycryptodome</code> \u2013 Encrypting personal data during collection [Local] (Added for privacy)</li> <li>[ ] <code>Apache Airflow</code> \u2013 Pipeline orchestration for complex workflows [Hybrid]</li> <li>[ ] <code>Prefect</code> \u2013 Python-native pipeline orchestration for smaller projects [Local] (Added as lightweight alternative)</li> </ul>"},{"location":"resources/tools-checklist/#2-data-storage-management","title":"2. Data Storage &amp; Management","text":"<ul> <li>[ ] <code>SQLite</code> \u2013 Lightweight storage for structured personal data [Local]</li> <li>[ ] <code>DuckDB</code> \u2013 Embedded analytical querying for personal datasets [Local]</li> <li>[ ] <code>MinIO</code> \u2013 Self-hosted object storage for multimedia [Local]</li> <li>[ ] <code>AWS S3</code> \u2013 Scalable object storage for large datasets [Cloud]</li> <li>[ ] <code>Cryptomator</code> \u2013 Encrypted local file vaults for sensitive data [Local] (Added for privacy)</li> <li>[ ] <code>Weaviate</code> \u2013 Vector DB for semantic search of personal data [Hybrid]</li> <li>[ ] <code>Chroma</code> \u2013 Lightweight vector storage for embeddings [Local] (Added as simpler alternative)</li> <li>[ ] <code>DVC</code> \u2013 Data versioning for reproducibility [Local]</li> <li>[ ] <code>Git LFS</code> \u2013 Versioning large media files (e.g., videos) [Hybrid] (Added for media)</li> </ul>"},{"location":"resources/tools-checklist/#3-data-preprocessing-feature-engineering","title":"3. Data Preprocessing &amp; Feature Engineering","text":"<ul> <li>[ ] <code>Pandas</code> \u2013 Data wrangling for text and tabular data [Local]</li> <li>[ ] <code>Polars</code> \u2013 High-performance data wrangling [Local]</li> <li>[ ] <code>NumPy</code> \u2013 Numerical operations for feature extraction [Local]</li> <li>[ ] <code>scikit-learn</code> \u2013 Classic feature engineering (e.g., TF-IDF) [Local]</li> <li>[ ] <code>spaCy</code> \u2013 NLP for personal writings and texts [Local]</li> <li>[ ] <code>Hugging Face Transformers</code> \u2013 Advanced NLP and embeddings [Local]</li> <li>[ ] <code>sentence-transformers</code> \u2013 Generating embeddings for KAG [Local] (Added for semantic features)</li> <li>[ ] <code>librosa</code> \u2013 Audio preprocessing for music/voice [Local] (Added for multimodal)</li> <li>[ ] <code>torchaudio</code> \u2013 Audio feature extraction for speech/music [Local] (Added for multimodal)</li> <li>[ ] <code>OpenCV</code> \u2013 Vision preprocessing for personal images/art [Local]</li> <li>[ ] <code>PIL</code> \u2013 Image manipulation for preprocessing [Local]</li> <li>[ ] <code>Featuretools</code> \u2013 Automated feature extraction from metadata [Local] (Added for efficiency)</li> </ul>"},{"location":"resources/tools-checklist/#4-model-development","title":"4. Model Development","text":"<ul> <li>[ ] <code>PyTorch</code> \u2013 Core framework for LLM development [Local]</li> <li>[ ] <code>Hugging Face Transformers</code> \u2013 Prebuilt architectures for fine-tuning [Hybrid]</li> <li>[ ] <code>peft</code> \u2013 Efficient fine-tuning with LoRA/adapters [Local] (Added for KAG)</li> <li>[ ] <code>OpenLLM</code> \u2013 Specialized LLM tools for personalization [Hybrid]</li> <li>[ ] <code>LLaMA.cpp</code> \u2013 Efficient local inference for small models [Local]</li> <li>[ ] <code>llama-cpp-python</code> \u2013 Python bindings for LLaMA.cpp [Local]</li> <li>[ ] <code>NanoGPT</code> \u2013 Lightweight LLM prototyping [Local] (Added for small-scale experiments)</li> <li>[ ] <code>trl</code> \u2013 Reinforcement learning for value alignment [Local]</li> <li>[ ] <code>FastAI</code> \u2013 High-level API for quick prototyping [Local]</li> </ul>"},{"location":"resources/tools-checklist/#5-model-training-infrastructure","title":"5. Model Training Infrastructure","text":"<ul> <li>[ ] <code>Weights &amp; Biases</code> \u2013 Experiment tracking for training runs [Hybrid]</li> <li>[ ] <code>MLflow</code> \u2013 Lightweight experiment tracking [Local]</li> <li>[ ] <code>HuggingFace Accelerate</code> \u2013 Distributed training on local GPUs [Local]</li> <li>[ ] <code>DeepSpeed</code> \u2013 Optimizing large-scale training [Hybrid]</li> <li>[ ] <code>Docker</code> \u2013 Containerization for reproducible environments [Local]</li> <li>[ ] <code>Podman</code> \u2013 Lightweight containerization alternative [Local]</li> <li>[ ] <code>optimum</code> \u2013 NVIDIA GPU optimization for local training [Local] (Added for efficiency)</li> <li>[ ] <code>Colab Pro</code> \u2013 Cloud-based prototyping for small models [Cloud] (Added for low-cost testing)</li> <li>[ ] <code>RunPod</code> \u2013 GPU rental for large-scale training [Cloud]</li> </ul>"},{"location":"resources/tools-checklist/#6-evaluation-benchmarking","title":"6. Evaluation &amp; Benchmarking","text":"<ul> <li>[ ] <code>lm-eval-harness</code> \u2013 LLM benchmarking for reasoning/coherence [Local]</li> <li>[ ] <code>MT-Bench</code> \u2013 Conversational evaluation for LLMs [Local]</li> <li>[ ] <code>ROUGE</code> \u2013 Text similarity metrics for style alignment [Local] (Added for custom evaluation)</li> <li>[ ] <code>BERTScore</code> \u2013 Semantic similarity for personal data [Local] (Added for custom evaluation)</li> <li>[ ] <code>scikit-learn</code> \u2013 General metric calculations [Local]</li> <li>[ ] <code>Great Expectations</code> \u2013 Data quality testing [Local]</li> <li>[ ] <code>Pandera</code> \u2013 Schema validation for datasets [Local]</li> <li>[ ] <code>pytest</code> \u2013 Custom tests for alignment with beliefs [Local]</li> <li>[ ] <code>SHAP</code> \u2013 Model interpretability for data influence [Local] (Added for transparency)</li> </ul>"},{"location":"resources/tools-checklist/#7-deployment-serving","title":"7. Deployment &amp; Serving","text":"<ul> <li>[ ] <code>FastAPI</code> \u2013 Local API for model serving [Local]</li> <li>[ ] <code>Gradio</code> \u2013 Interactive UI for model interaction [Local]</li> <li>[ ] <code>Panel</code> \u2013 Dashboard for data/model visualization [Local] (Added for user interface)</li> <li>[ ] <code>vLLM</code> \u2013 Efficient LLM inference serving [Local]</li> <li>[ ] <code>TGI</code> \u2013 Text generation inference for LLMs [Hybrid] (Added for optimized serving)</li> <li>[ ] <code>ONNX</code> \u2013 Optimized model format for deployment [Local]</li> <li>[ ] <code>Nginx</code> \u2013 Reverse proxy for secure serving [Hybrid]</li> <li>[ ] <code>Modal</code> \u2013 Serverless deployment for scalability [Cloud]</li> <li>[ ] <code>Keycloak</code> \u2013 User authentication for shared access [Hybrid] (Added for security)</li> </ul>"},{"location":"resources/tools-checklist/#8-retrieval-augmented-generation-rag-specific","title":"8. Retrieval-Augmented Generation (RAG) Specific","text":"<ul> <li>[ ] <code>LlamaIndex</code> \u2013 RAG orchestration for personal data [Local]</li> <li>[ ] <code>LangChain</code> \u2013 Flexible RAG pipelines [Hybrid]</li> <li>[ ] <code>Chroma</code> \u2013 Lightweight vector storage for retrieval [Local]</li> <li>[ ] <code>FAISS</code> \u2013 Local vector retrieval for embeddings [Local]</li> <li>[ ] <code>RAGAS</code> \u2013 Evaluation of RAG performance [Local] (Added for tuning)</li> </ul>"},{"location":"resources/tools-checklist/#notes-on-deployment-strategies","title":"Notes on Deployment Strategies","text":"<ul> <li>Local: Tools designed for personal hardware (e.g., laptop, GPU workstation) to prioritize privacy and cost-efficiency. Ideal for initial prototyping and personal use with your 4GB+ dataset.</li> <li>Cloud: Scalable, resource-intensive tools for large datasets or training larger models (e.g., 1B parameters). Useful for future scaling but may involve costs and privacy considerations.</li> <li>Hybrid: Tools that can run locally or in the cloud, offering flexibility. Suitable for transitioning from local experiments to cloud-based scaling or for tools with optional cloud integrations (e.g., Hugging Face).</li> </ul>"},{"location":"resources/tools/","title":"Toolchain for Semblance AI","text":""},{"location":"resources/tools/#full-toolchain-from-data-curation-to-benchmarking","title":"Full Toolchain (from Data Curation to Benchmarking)","text":""},{"location":"resources/tools/#1-data-collection-curation","title":"1. Data Collection &amp; Curation","text":"Tool Description URL Scrapy Web scraping framework for user-approved online content (e.g., personal blogs) https://scrapy.org/ BeautifulSoup Lightweight library for parsing HTML/XML for specific data extraction https://www.crummy.com/software/BeautifulSoup/ yt-dlp Tool for downloading video/audio from personal media (e.g., YouTube playlists) https://github.com/yt-dlp/yt-dlp ffmpeg Multimedia processing for extracting video/audio data https://ffmpeg.org/ pdfminer.six PDF parsing library for extracting text from documents (e.g., personal papers) https://github.com/pdfminer/pdfminer.six PyMuPDF High-performance PDF and document parsing library https://pymupdf.readthedocs.io/ unstructured Library for parsing complex documents (e.g., mixed text/image files) https://github.com/Unstructured-IO/unstructured pypandoc Document format conversion (e.g., Markdown to text) https://github.com/JessicaTegner/pypandoc ebooklib Library for parsing ePub files from personal book collections https://github.com/aerkalov/ebooklib music21 Toolkit for analyzing music scores or metadata for musical preferences https://web.mit.edu/music21/ Label Studio Annotation platform for tagging personal data (e.g., ethical stances) https://labelstudio.ai/ Streamlit Framework for building user-friendly interfaces for manual data upload/tagging https://streamlit.io/ pycryptodome Library for encrypting personal data during collection https://www.pycryptodome.org/ Apache Airflow Workflow orchestration for complex data collection pipelines https://airflow.apache.org/ Prefect Python-native orchestration for smaller data workflows https://www.prefect.io/"},{"location":"resources/tools/#2-data-storage-management","title":"2. Data Storage &amp; Management","text":"Tool Description URL SQLite Lightweight database for structured personal data https://www.sqlite.org/ DuckDB Embedded database for analytical querying of personal datasets https://duckdb.org/ MinIO Self-hosted object storage for multimedia data https://min.io/ AWS S3 Scalable cloud object storage for large datasets https://aws.amazon.com/s3/ Cryptomator Encrypted local file vaults for sensitive data https://cryptomator.org/ Weaviate Vector database for semantic search of personal data https://weaviate.io/ Chroma Lightweight vector storage for embeddings https://www.trychroma.com/ DVC Data versioning tool for reproducibility https://dvc.org/ Git LFS Versioning for large media files (e.g., videos) https://git-lfs.github.com/"},{"location":"resources/tools/#3-data-preprocessing-feature-engineering","title":"3. Data Preprocessing &amp; Feature Engineering","text":"Tool Description URL Pandas Data wrangling for text and tabular data https://pandas.pydata.org/ Polars High-performance data wrangling library https://www.pola.rs/ NumPy Numerical operations for feature extraction https://numpy.org/ scikit-learn Classic feature engineering (e.g., TF-IDF) https://scikit-learn.org/ spaCy NLP library for processing personal writings and texts https://spacy.io/ Hugging Face Transformers Advanced NLP and embeddings for text processing https://huggingface.co/ sentence-transformers Generating embeddings for knowledge-augmented generation https://www.sbert.net/ librosa Audio preprocessing for music or voice data https://librosa.org/ torchaudio Audio feature extraction for speech or music https://pytorch.org/audio/ OpenCV Vision preprocessing for personal images or art https://opencv.org/ PIL Image manipulation for preprocessing https://pillow.readthedocs.io/ Featuretools Automated feature extraction from metadata https://www.featuretools.com/"},{"location":"resources/tools/#4-model-development","title":"4. Model Development","text":"Tool Description URL PyTorch Core framework for LLM development https://pytorch.org/ Hugging Face Transformers Prebuilt architectures for fine-expanded model tuning https://huggingface.co/ peft Efficient fine-tuning with LoRA/adapters https://github.com/huggingface/peft OpenLLM Specialized tools for personalized LLMs https://github.com/bentoml/OpenLLM LLaMA.cpp Efficient local inference for small models https://github.com/ggerganov/llama.cpp llama-cpp-python Python bindings for LLaMA.cpp https://github.com/abetlen/llama-cpp-python NanoGPT Lightweight LLM prototyping framework https://github.com/karpathy/nanoGPT trl Reinforcement learning for value alignment https://github.com/huggingface/trl FastAI High-level API for quick model prototyping https://www.fast.ai/"},{"location":"resources/tools/#5-model-training-infrastructure","title":"5. Model Training Infrastructure","text":"Tool Description URL Weights &amp; Biases Experiment tracking for training runs https://wandb.ai/ MLflow Lightweight experiment tracking https://mlflow.org/ HuggingFace Accelerate Distributed training on local GPUs https://huggingface.co/docs/accelerate DeepSpeed Optimizing large-scale training https://www.deepspeed.ai/ Docker Containerization for reproducible environments https://www.docker.com/ Podman Lightweight containerization alternative https://podman.io/ optimum NVIDIA GPU optimization for local training https://huggingface.co/docs/optimum Colab Pro Cloud-based prototyping for small models https://colab.google/ RunPod GPU rental for large-scale training https://www.runpod.io/"},{"location":"resources/tools/#6-evaluation-benchmarking","title":"6. Evaluation &amp; Benchmarking","text":"Tool Description URL lm-eval-harness LLM benchmarking for reasoning and coherence https://github.com/EleutherAI/lm-evaluation-harness MT-Bench Conversational evaluation for LLMs https://github.com/lmsys/lm-sys ROUGE Text similarity metrics for style alignment https://github.com/pltrdy/rouge BERTScore Semantic similarity for personal data https://github.com/Tiiiger/bert_score scikit-learn General metric calculations https://scikit-learn.org/ Great Expectations Data quality testing https://greatexpectations.io/ Pandera Schema validation for datasets https://pandera.readthedocs.io/ pytest Custom tests for alignment with beliefs https://pytest.org/ SHAP Model interpretability for data influence https://shap.readthedocs.io/"},{"location":"resources/tools/#7-deployment-serving","title":"7. Deployment &amp; Serving","text":"Tool Description URL FastAPI Local API for model serving https://fastapi.tiangolo.com/ Gradio Interactive UI for model interaction https://gradio.app/ Panel Dashboard for data/model visualization https://panel.holoviz.org/ vLLM Efficient LLM inference serving https://vllm.ai/ TGI Text generation inference for LLMs https://github.com/huggingface/text-generation-inference ONNX Optimized model format for deployment https://onnx.ai/ Nginx Reverse proxy for secure serving https://nginx.org/ Modal Serverless deployment for scalability https://modal.com/ Keycloak User authentication for shared access https://www.keycloak.org/"},{"location":"resources/tools/#8-retrieval-augmented-generation-rag-specific","title":"8. Retrieval-Augmented Generation (RAG) Specific","text":"Tool Description URL LlamaIndex RAG orchestration for personal data https://www.llamaindex.ai/ LangChain Flexible RAG pipelines https://www.langchain.com/ Chroma Lightweight vector storage for retrieval https://www.trychroma.com/ FAISS Local vector retrieval for embeddings https://github.com/facebookresearch/faiss RAGAS Evaluation of RAG performance https://github.com/explosion/ragas"},{"location":"resources/tools/#notes-on-deployment-strategies","title":"Notes on Deployment Strategies","text":"<ul> <li>Local: Tools designed for personal hardware (e.g., laptop, GPU workstation) to prioritize privacy and cost-efficiency. Ideal for initial prototyping and personal use with your 4GB+ dataset.</li> <li>Cloud: Scalable, resource-intensive tools for large datasets or training larger models (e.g., 1B parameters). Useful for future scaling but may involve costs and privacy considerations.</li> <li>Hybrid: Tools that can run locally or in the cloud, offering flexibility. Suitable for transitioning from local experiments to cloud-based scaling or for tools with optional cloud integrations (e.g., Hugging Face).</li> </ul>"}]}